%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Saved with string encoding Unicode (UTF-8) 

@article{sample,
	Author = {F. Hogehoge},
	Date-Added = {2016-06-15 05:19:05 +0000},
	Date-Modified = {2016-06-15 05:20:21 +0000},
	Journal = {Nuclear Instruments and Methods in Physics Research A},
	Title = {Sample article},
	Year = {2016}}

@misc{iLCSoft,
    author = {},
    title = {iLCSoft},
    howpublished = {\url{https://github.com/iLCSoft}},
    month = {},
    year = {},
}	

@misc{LCFIPlus,
    author = {},
    title = {lcfiplus/LCFIPlus: Flavor tagging code for ILC detectors},
    howpublished = {\url{https://github.com/lcfiplus/LCFIPlus}},
    month = {},
    year = {},
}
	
@article{RecommendationsonILCProjectImplementation,
    author = "Desch, Klaus and others",
    collaboration = "KEK International Working Group",
    title = "{Recommendations on ILC Project Implementation}",
    month = "9",
    year = "2019"
}
	
@article{PatternRecognitionUsingGeneralizedPortraitMethod,
    author="VAPNIK, V.",
    title="Pattern recognition using generalized portrait method",
    journal="Automation and Remote Control",
    ISSN="",
    publisher="",
    year="1963",
    month="",
    volume="24",
    number="",
    pages="774-780",
    URL="https://ci.nii.ac.jp/naid/10020952249/",
    DOI="",
}

@article{TrainingAlgorithmforOptimalMarginClassifiers,
    author="BOSER, B. E.",
    title="A Training Algorithm for Optimal Margin Classifiers",
    journal="Proceedings of the 5th Annual ACM Workshop on Computational Learning Theory, Pittsburgh,    Pennsylvania, United States (1992-7)",
    ISSN="",
    publisher="",
    year="1992",
    month="",
    volume="",
    number="",
    pages="",
    URL="https://ci.nii.ac.jp/naid/10015672253/",
    DOI="",
}

@misc{GlobalProject,
      title={The International Linear Collider: A Global Project}, 
      author={Philip Bambade and Tim Barklow and Ties Behnke and Mikael Berggren and James Brau and Philip Burrows and Dmitri Denisov and Angeles Faus-Golfe and Brian Foster and Keisuke Fujii and Juan Fuster and Frank Gaede and Paul Grannis and Christophe Grojean and Andrew Hutton and Benno List and Jenny List and Shinichiro Michizono and Akiya Miyamoto and Olivier Napoly and Michael Peskin and Roman Poeschl and Frank Simon and Jan Strube and Junping Tian and Maksym Titov and Marcel Vos and Andrew White and Graham Wilson and Akira Yamamoto and Hitoshi Yamamoto and Kaoru Yokoya},
      year={2019},
      eprint={1903.01629},
      archivePrefix={arXiv},
      primaryClass={hep-ex}
}

@misc{InterimDesignReport,
      title={International Large Detector: Interim Design Report}, 
      author={The ILD Collaboration},
      year={2020},
      eprint={2003.01116},
      archivePrefix={arXiv},
      primaryClass={physics.ins-det}
}

@misc{TechnicalDesignReportPhysics,
      title={The International Linear Collider Technical Design Report - Volume 2: Physics}, 
      author={Howard Baer and Tim Barklow and Keisuke Fujii and Yuanning Gao and Andre Hoang and Shinya Kanemura and Jenny List and Heather E. Logan and Andrei Nomerotski and Maxim Perelstein and Michael E. Peskin and Roman P\UTF{00F6}schl and J\UTF{00FC}rgen Reuter and Sabine Riemann and Aurore Savoy-Navarro and Geraldine Servant and Tim M. P. Tait and Jaehoon Yu},
      year={2013},
      eprint={1306.6352},
      archivePrefix={arXiv},
      primaryClass={hep-ph}
}

@book{ZeroDeepLearning1,
    author = {斎藤 康毅},
    title={ゼロから作るDeep Learning: Pythonで学ぶディープラーニングの理論と実装},
    isbn={9784873117584},
    series={ゼロから作るDeep Learning},
    url={https://www.oreilly.co.jp/books/9784873117584/},
    month = "9",
    year={2016},
    publisher={オライリー・ジャパン}
}

@book{ZeroDeepLearning2,
    author = {斎藤 康毅},
    title={ゼロから作るDeep Learning 2: 自然言語処理編},
    isbn={9784873118369},
    series={ゼロから作るDeep Learning},
    url={https://www.oreilly.co.jp/books/9784873118369},
    month = "7",
    year={2018},
    publisher={オライリー・ジャパン}
}

@book{PythonMLPrograming,
    author    = "Raschka, Sebastian and クイープ and 福島, 真太朗",
    title     = "Python機械学習プログラミング : 達人データサイエンティストによる理論と実践",
    publisher = "インプレス",
    year      = "2016",
    series    = "Impress top gear",
    number    = "",
    URL       = "https://ci.nii.ac.jp/ncid/BB21521206"
}

@article{LCFIPlusPaper,
   title={LCFIPlus: A framework for jet analysis in linear collider studies},
   volume={808},
   ISSN={0168-9002},
   url={http://dx.doi.org/10.1016/j.nima.2015.11.054},
   DOI={10.1016/j.nima.2015.11.054},
   journal={Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
   publisher={Elsevier BV},
   author={Suehara, Taikan and Tanabe, Tomohiko},
   year={2016},
   month={Feb},
   pages={109\UTF{2013}116}
}

@article{TrackParametersLCIO,
    author = "Kramer, Thomas",
    title = "{Track parameters in LCIO}",
    reportNumber = "LC-DET-2006-004",
    month = "8",
    year = "2006"
}

@article{PerceptronPaper,
author="Rosenblatt, F.",
title="The perceptron: A probabilistic model for information storage and organization in the brain",
journal="Psyhological Review",
ISSN="",
publisher="",
year="1958",
month="",
volume="65",
number="6",
pages="386-408",
URL="https://ci.nii.ac.jp/naid/20001617891/",
DOI="",
}

@article{Dartmouth,
  added-at = {2020-07-20T00:00:00.000+0200},
  author = {McCarthy, John and Minsky, Marvin and Rochester, Nathaniel and Shannon, Claude E.},
  biburl = {https://www.bibsonomy.org/bibtex/2bd187621e003f7aed003c3ddd44acfbb/dblp},
  ee = {https://doi.org/10.1609/aimag.v27i4.1904},
  interhash = {f359fffd134596aa1f608cbd91f15c18},
  intrahash = {bd187621e003f7aed003c3ddd44acfbb},
  journal = {AI Magazine},
  keywords = {dblp},
  number = 4,
  pages = {12-14},
  timestamp = {2020-07-24T00:24:37.000+0200},
  title = {A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, August 31, 1955.},
  url = {http://dblp.uni-trier.de/db/journals/aim/aim27.html#McCarthyMRS06},
  volume = 27,
  year = 2006
}


@article{ApproximationSuperpositionsSigmoidalFunction,
author="CYBENKO, G.",
title="Approximation by superpositions of a sigmoidal function",
journal="Mathematics of Control, Signals and Systems",
ISSN="",
publisher="",
year="1989",
month="",
volume="2",
number="",
pages="303-314",
URL="https://ci.nii.ac.jp/naid/30024206829/",
DOI="10.1007/BF02551274",
}

@misc{TensorflowWeb,
author = {},
title = {TensorFlow},
howpublished = {\url{https://www.tensorflow.org/?hl=ja}},
month = {},
year = {},
}

@misc{KerasWeb,
author = {},
title = {Home - Keras Documentation},
howpublished = {\url{https://keras.io/ja/}},
month = {},
year = {},
}

@misc{PyTorchWeb,
author = {},
title = {PyTorch},
howpublished = {\url{https://pytorch.org/}},
month = {},
year = {},
}

@misc{ChainerWeb,
author = {},
title = {Chainer: A flexible framework for neural networks},
howpublished = {\url{https://chainer.org/}},
month = {},
year = {},
}

@misc{CaffeWeb,
author = {},
title = {Caffe | Deep Learning Framework},
howpublished = {\url{http://caffe.berkeleyvision.org/}},
month = {},
year = {},
}

@Article{SGD,
author = "B. Widrow and M. E. Hoff",
title = "Adaptive Switching Circuits",
journal = "1960 IRE WESCON Convention Record",
publisher = "IRE",
year = "1960",
pages = "96--104",
note = "Reprinted in {\sl Neurocomputing} MIT Press, 1988 .",
}

@misc{RMSProp,
  title={{Lecture 6.5---rmsProp: Divide the gradient by a running average of its recent magnitude}},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

@misc{Adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Backpropagation,
	doi = {10.1038/323533a0},
	url = {https://doi.org/10.1038%2F323533a0},
	year = 1986,
	month = {oct},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {323},
	number = {6088},
	pages = {533--536},
	author = {David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
	title = {Learning representations by back-propagating errors},
	journal = {Nature}
}

@article {Autoencoder,
	title = {Reducing the Dimensionality of Data with Neural Networks},
	volume = {313},
	number = {5786},
	pages = {504--507},
	author = {Geoffrey E. Hinton and Ruslan Russ Salakhutdinov},
	year = {2006},
	doi = {10.1126/science.1127647},
	publisher = {American Association for the Advancement of Science},
	abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such {\textquotedblleft}autoencoder{\textquotedblright} networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/313/5786/504},
	journal = {Science}
}

@misc{GenerativeAdversarialNetworks,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{LSTMpaper,
author = {Hochreiter, Sepp and Schmidhuber, J\UTF{00FC}rgen},
title = {Long Short-Term Memory},
journal = {Neural Computation},
volume = {9},
number = {8},
pages = {1735-1780},
year = {1997},
doi = {10.1162/neco.1997.9.8.1735},
URL = {https://doi.org/10.1162/neco.1997.9.8.1735},
eprint = {https://doi.org/10.1162/neco.1997.9.8.1735},
abstract = { Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms. }
}

@misc{GRU,
      title={Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}, 
      author={Kyunghyun Cho and Bart van Merrienboer and Caglar Gulcehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio},
      year={2014},
      eprint={1406.1078},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{LuongAttention,
      title={Effective Approaches to Attention-based Neural Machine Translation}, 
      author={Minh-Thang Luong and Hieu Pham and Christopher D. Manning},
      year={2015},
      eprint={1508.04025},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{BahdanauAttention,
      title={Neural Machine Translation by Jointly Learning to Align and Translate}, 
      author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
      year={2016},
      eprint={1409.0473},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{AttentionIsAllYouNeed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}