\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{ZeroDeepLearning1}
\citation{ZeroDeepLearning2}
\citation{PythonMLPrograming}
\@writefile{toc}{\contentsline {chapter}{\numberline {第2章}深層学習}{20}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\jsc@mpt }}
\@writefile{lot}{\addvspace {10\jsc@mpt }}
\newlabel{chap:DeepLearning}{{2}{20}{深層学習}{chapter.2}{}}
\citation{Dartmouth}
\citation{PatternRecognitionUsingGeneralizedPortraitMethod}
\citation{TrainingAlgorithmforOptimalMarginClassifiers}
\citation{PerceptronPaper}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}機械学習と深層学習}{21}{section.2.1}\protected@file@percent }
\newlabel{DL:MachineandDeepLearning}{{2.1}{21}{機械学習と深層学習}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 機械学習の中の深層学習の位置付け\relax }}{22}{figure.caption.13}\protected@file@percent }
\newlabel{1MachineLearning}{{2.1}{22}{機械学習の中の深層学習の位置付け\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}パーセプトロン}{22}{section.2.2}\protected@file@percent }
\newlabel{DL:Perceptron}{{2.2}{22}{パーセプトロン}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}単純パーセプトロン}{22}{subsection.2.2.1}\protected@file@percent }
\newlabel{DL:Percep:SimplePerceptron}{{2.2.1}{22}{単純パーセプトロン}{subsection.2.2.1}{}}
\citation{ApproximationSuperpositionsSigmoidalFunction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces 単純パーセプトロン\relax }}{23}{figure.caption.14}\protected@file@percent }
\newlabel{2SimplePerceptron}{{2.2}{23}{単純パーセプトロン\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces ヘヴィサイドの階段関数\relax }}{23}{figure.caption.15}\protected@file@percent }
\newlabel{3HeavisideStepFunction}{{2.3}{23}{ヘヴィサイドの階段関数\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}多層パーセプトロン}{23}{subsection.2.2.2}\protected@file@percent }
\newlabel{DL:Percep:MultiLayerPerceptron}{{2.2.2}{23}{多層パーセプトロン}{subsection.2.2.2}{}}
\citation{TensorflowWeb}
\citation{KerasWeb}
\citation{PyTorchWeb}
\citation{CaffeWeb}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces 多層パーセプトロン\relax }}{24}{figure.caption.16}\protected@file@percent }
\newlabel{4MultiLayerPerceptron}{{2.4}{24}{多層パーセプトロン\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}ニューラルネットワーク}{24}{section.2.3}\protected@file@percent }
\newlabel{DL:NeuralNetwork}{{2.3}{24}{ニューラルネットワーク}{section.2.3}{}}
\citation{ReLUpaper}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}ニューラルネットワークの構造}{25}{subsection.2.3.1}\protected@file@percent }
\newlabel{DL:NN:StructureofNN}{{2.3.1}{25}{ニューラルネットワークの構造}{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces 活性化関数\relax }}{26}{figure.caption.17}\protected@file@percent }
\newlabel{5ActivationFunction}{{2.5}{26}{活性化関数\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces ニューラルネットワーク\relax }}{26}{figure.caption.18}\protected@file@percent }
\newlabel{6NeuralNetwork}{{2.6}{26}{ニューラルネットワーク\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}ニューラルネットワークの学習}{27}{subsection.2.3.2}\protected@file@percent }
\newlabel{DL:NN:TrainingofNN}{{2.3.2}{27}{ニューラルネットワークの学習}{subsection.2.3.2}{}}
\citation{SGD}
\citation{RMSProp}
\citation{Adam}
\citation{Backpropagation}
\citation{Autoencoder}
\citation{GenerativeAdversarialNetworks}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}ディープニューラルネットワーク}{30}{subsection.2.3.3}\protected@file@percent }
\newlabel{DL:NN:DeepNeuralNetwork}{{2.3.3}{30}{ディープニューラルネットワーク}{subsection.2.3.3}{}}
\citation{LSTMpaper}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}リカレントニューラルネットワーク}{31}{section.2.4}\protected@file@percent }
\newlabel{DL:RecurrentNeuralNetwork}{{2.4}{31}{リカレントニューラルネットワーク}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}リカレントニューラルネットワークの構造と学習}{31}{subsection.2.4.1}\protected@file@percent }
\newlabel{DL:RNN:ReccurentNeuralNetwork}{{2.4.1}{31}{リカレントニューラルネットワークの構造と学習}{subsection.2.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces リカレントニューラルネットワーク\relax }}{32}{figure.caption.19}\protected@file@percent }
\newlabel{7RecurrentNeuralNetwork}{{2.7}{32}{リカレントニューラルネットワーク\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces リカレントニューラルネットワークの重み\relax }}{32}{figure.caption.20}\protected@file@percent }
\newlabel{8RNNWeight}{{2.8}{32}{リカレントニューラルネットワークの重み\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces リカレントニューラルネットワークの出力方法\relax }}{33}{figure.caption.21}\protected@file@percent }
\newlabel{9RNNOutputs}{{2.9}{33}{リカレントニューラルネットワークの出力方法\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}リカレントニューラルネットワークの問題点}{33}{subsection.2.4.2}\protected@file@percent }
\newlabel{DL:RNN:IssueofRNN}{{2.4.2}{33}{リカレントニューラルネットワークの問題点}{subsection.2.4.2}{}}
\citation{GRU}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}長・短期記憶 (Long Short-Term Memory, LSTM)}{34}{subsection.2.4.3}\protected@file@percent }
\newlabel{DL:RNN:LongShortTermMemory}{{2.4.3}{34}{長・短期記憶 (Long Short-Term Memory, LSTM)}{subsection.2.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces LSTMの流れ\relax }}{35}{figure.caption.22}\protected@file@percent }
\newlabel{10LongShortTermMemory}{{2.10}{35}{LSTMの流れ\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces 単体のLSTM\relax }}{35}{figure.caption.23}\protected@file@percent }
\newlabel{11LSTM}{{2.11}{35}{単体のLSTM\relax }{figure.caption.23}{}}
\newlabel{12ForgetGate}{{2.12a}{37}{忘却ゲート\relax }{figure.caption.24}{}}
\newlabel{sub@12ForgetGate}{{a}{37}{忘却ゲート\relax }{figure.caption.24}{}}
\newlabel{13InputGate}{{2.12b}{37}{入力ゲート\relax }{figure.caption.24}{}}
\newlabel{sub@13InputGate}{{b}{37}{入力ゲート\relax }{figure.caption.24}{}}
\newlabel{14CellUpdate}{{2.12c}{37}{セルの更新\relax }{figure.caption.24}{}}
\newlabel{sub@14CellUpdate}{{c}{37}{セルの更新\relax }{figure.caption.24}{}}
\newlabel{15OutputGate}{{2.12d}{37}{出力ゲート\relax }{figure.caption.24}{}}
\newlabel{sub@15OutputGate}{{d}{37}{出力ゲート\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces LSTMの各ゲートについての図解\relax }}{37}{figure.caption.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Stacked LSTM\relax }}{37}{figure.caption.25}\protected@file@percent }
\newlabel{16StackedLSTM}{{2.13}{37}{Stacked LSTM\relax }{figure.caption.25}{}}
\citation{BahdanauAttention}
\citation{LuongAttention}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces 双方向LSTM\relax }}{38}{figure.caption.26}\protected@file@percent }
\newlabel{17BidirectionalLSTM}{{2.14}{38}{双方向LSTM\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Attention}{38}{section.2.5}\protected@file@percent }
\newlabel{DL:Attention}{{2.5}{38}{Attention}{section.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}エンコーダー・デコーダーモデル}{38}{subsection.2.5.1}\protected@file@percent }
\newlabel{DL:Atten:EncoderDecoderModel}{{2.5.1}{38}{エンコーダー・デコーダーモデル}{subsection.2.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces LSTMによるエンコーダー・デコーダーモデル\relax }}{39}{figure.caption.27}\protected@file@percent }
\newlabel{18EncoderDecoderLSTM}{{2.15}{39}{LSTMによるエンコーダー・デコーダーモデル\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Attention}{39}{subsection.2.5.2}\protected@file@percent }
\newlabel{DL:Atten:Attention}{{2.5.2}{39}{Attention}{subsection.2.5.2}{}}
\citation{BahdanauAttention}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces AttentionとLSTMによるエンコーダー・デコーダーモデル\relax }}{40}{figure.caption.28}\protected@file@percent }
\newlabel{19EncoderDecoderAttention}{{2.16}{40}{AttentionとLSTMによるエンコーダー・デコーダーモデル\relax }{figure.caption.28}{}}
\citation{LuongAttention}
\citation{AttentionIsAllYouNeed}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Additive Attention と Dot-Product Attention\relax }}{41}{figure.caption.29}\protected@file@percent }
\newlabel{20Attention}{{2.17}{41}{Additive Attention と Dot-Product Attention\relax }{figure.caption.29}{}}
\citation{GitHubGotoK}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}ハイパーパラメータ}{42}{section.2.6}\protected@file@percent }
\newlabel{DL:HyperParameter}{{2.6}{42}{ハイパーパラメータ}{section.2.6}{}}
\@setckpt{Chapter/2DeepLearning}{
\setcounter{page}{43}
\setcounter{equation}{33}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{8}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{17}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{3}
\setcounter{Hfootnote}{8}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{28}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{4}
\setcounter{section@level}{1}
}
