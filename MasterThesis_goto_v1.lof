\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {1.1}{\ignorespaces 標準模型の素粒子\relax }}{11}{figure.caption.4}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces ILCの全体像}}{12}{figure.caption.5}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces ILC計画の今後}}{12}{figure.caption.6}%
\contentsline {figure}{\numberline {1.4}{\ignorespaces 重心系エネルギーとヒッグス事象生成断面積の関係}}{13}{figure.caption.7}%
\contentsline {figure}{\numberline {1.5}{\ignorespaces International Large Detector (ILD) \relax }}{15}{figure.caption.8}%
\contentsline {figure}{\numberline {1.6}{\ignorespaces primary vertexとsecondary vertexの図示}}{18}{figure.caption.11}%
\contentsline {figure}{\numberline {1.7}{\ignorespaces 深層学習によるジェットの再構成}}{19}{figure.caption.12}%
\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {2.1}{\ignorespaces 機械学習の中の深層学習の位置付け}}{22}{figure.caption.13}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces 単純パーセプトロン}}{23}{figure.caption.14}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces ヘヴィサイドの階段関数\relax }}{24}{figure.caption.15}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces 多層パーセプトロン}}{24}{figure.caption.16}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces 活性化関数\relax }}{26}{figure.caption.17}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces ニューラルネットワーク}}{26}{figure.caption.18}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces リカレントニューラルネットワーク}}{32}{figure.caption.19}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces リカレントニューラルネットワークの重みの明示的な表現}}{33}{figure.caption.20}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces リカレントニューラルネットワークの出力方法}}{34}{figure.caption.21}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces LSTMの流れ}}{35}{figure.caption.22}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces 単体のLSTM}}{35}{figure.caption.23}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces LSTMの各ゲートについての図解}}{37}{figure.caption.24}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Stacked LSTM}}{38}{figure.caption.25}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces 双方向LSTM}}{39}{figure.caption.26}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces LSTMによるエンコーダー・デコーダーモデル}}{40}{figure.caption.27}%
\contentsline {figure}{\numberline {2.16}{\ignorespaces AttentionとLSTMによるエンコーダー・デコーダーモデル}}{41}{figure.caption.28}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Additive Attention と Dot-Product Attention\relax }}{42}{figure.caption.29}%
\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {3.1}{\ignorespaces 終状態$\rm b\bar {b}$での崩壊点の例}}{47}{figure.caption.32}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces 事象に含まれる飛跡の本数と崩壊点の個数}}{48}{figure.caption.33}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces トラック・パラメータの定義}}{48}{figure.caption.34}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces 変数の分布の例\relax }}{49}{figure.caption.35}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces LCFIPlusによって予想される崩壊点の位置の分布}}{50}{figure.caption.36}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces LCFIPlusによって予想される崩壊点の位置と$\chi ^2$値の相関}}{50}{figure.caption.37}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces 終状態$\rm b\bar {b}$での崩壊点\relax }}{53}{figure.caption.39}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces 飛跡対についてのネットワークの概略図}}{54}{figure.caption.40}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces 各終状態での分類クラスのデータ数の比}}{54}{figure.caption.41}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces 訓練データでの分類クラスのデータ数の比}}{55}{figure.caption.42}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces 評価のための飛跡対についてのネットワーク\relax }}{58}{figure.caption.44}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces ネットワークのスコアとクラス分類の効率の関係}}{59}{figure.caption.46}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces 各モデルのROC曲線}}{60}{figure.caption.47}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces 各モデルの混合行列と各モデルの相対値}}{61}{figure.caption.48}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces t-SNEによる次元削減の比較}}{63}{figure.caption.49}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces リカレントニューラルネットワークを用いた崩壊点生成}}{64}{figure.caption.50}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces 崩壊点生成のためのリカレントニューラルネットワーク構造}}{64}{figure.caption.51}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces 系列1ステップについての独自リカレントニューラルネットワーク構造}}{65}{figure.caption.52}%
\contentsline {figure}{\numberline {3.19}{\ignorespaces 独自リカレントニューラルネットワーク構造の解釈}}{66}{figure.caption.53}%
\contentsline {figure}{\numberline {3.20}{\ignorespaces Attentionを組み込んだエンコーダー・デコーダーモデルへの拡張}}{67}{figure.caption.54}%
\contentsline {figure}{\numberline {3.21}{\ignorespaces 独自リカレントニューラルネットワークのAttentionへの拡張}}{67}{figure.caption.55}%
\contentsline {figure}{\numberline {3.22}{\ignorespaces 飛跡順のシャッフル}}{70}{figure.caption.57}%
\contentsline {figure}{\numberline {3.23}{\ignorespaces 標準的なLSTMと独自のネットワークの比較}}{72}{figure.caption.59}%
\contentsline {figure}{\numberline {3.24}{\ignorespaces 各データ属性の効率とスコアの関係}}{72}{figure.caption.60}%
\contentsline {figure}{\numberline {3.25}{\ignorespaces 各データ属性のROC曲線}}{73}{figure.caption.61}%
\contentsline {figure}{\numberline {3.26}{\ignorespaces Attention Weight}}{75}{figure.caption.62}%
\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {4.1}{\ignorespaces 崩壊点検出アルゴリズム\relax }}{77}{figure.caption.63}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces 閾値とSVのタネの効率, 純度の関係}}{79}{figure.caption.64}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces 閾値とSVのタネの効率, 純度についてのPR曲線}}{80}{figure.caption.65}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces 同一の崩壊チェインと同一の親粒子}}{82}{figure.caption.66}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces 閾値と崩壊点検出の性能の関係}}{83}{figure.caption.67}%
\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {5.1}{\ignorespaces フレーバータギングの性能に関するROC曲線}}{89}{figure.caption.72}%
\addvspace {10\jsc@mpt }
\addvspace {10\jsc@mpt }
