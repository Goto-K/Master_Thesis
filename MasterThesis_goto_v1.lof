\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {1.1}{\ignorespaces 標準模型の素粒子\relax }}{12}{figure.caption.4}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces ILCの全体像}}{13}{figure.caption.5}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces ILC計画の今後}}{13}{figure.caption.6}%
\contentsline {figure}{\numberline {1.4}{\ignorespaces 重心系エネルギーとヒッグス事象生成断面積の関係}}{14}{figure.caption.7}%
\contentsline {figure}{\numberline {1.5}{\ignorespaces International Large Detector (ILD) \relax }}{16}{figure.caption.8}%
\contentsline {figure}{\numberline {1.6}{\ignorespaces primary vertexとsecondary vertexの図示}}{19}{figure.caption.13}%
\contentsline {figure}{\numberline {1.7}{\ignorespaces 深層学習によるジェットの再構成}}{20}{figure.caption.14}%
\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {2.1}{\ignorespaces 機械学習の中の深層学習の位置付け}}{23}{figure.caption.15}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces 単純パーセプトロン}}{24}{figure.caption.16}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces ヘヴィサイドの階段関数\relax }}{25}{figure.caption.17}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces 多層パーセプトロン}}{25}{figure.caption.18}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces 活性化関数\relax }}{27}{figure.caption.19}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces ニューラルネットワーク}}{27}{figure.caption.20}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces リカレントニューラルネットワーク}}{33}{figure.caption.21}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces リカレントニューラルネットワークの重みの明示的な表現}}{34}{figure.caption.22}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces リカレントニューラルネットワークの出力方法}}{35}{figure.caption.23}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces LSTMの流れ}}{36}{figure.caption.24}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces 単体のLSTM}}{36}{figure.caption.25}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces LSTMの各ゲートについての図解}}{38}{figure.caption.26}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Stacked LSTM}}{39}{figure.caption.27}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces 双方向LSTM}}{40}{figure.caption.28}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces LSTMによるエンコーダー・デコーダーモデル}}{41}{figure.caption.29}%
\contentsline {figure}{\numberline {2.16}{\ignorespaces AttentionとLSTMによるエンコーダー・デコーダーモデル}}{42}{figure.caption.30}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Additive Attention と Dot-Product Attention\relax }}{43}{figure.caption.31}%
\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {3.1}{\ignorespaces 終状態$\rm b\bar {b}$での崩壊点の例}}{48}{figure.caption.34}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces 事象に含まれる飛跡の本数と崩壊点の個数}}{48}{figure.caption.35}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces トラック・パラメータの定義}}{49}{figure.caption.36}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces 変数の分布の例\relax }}{50}{figure.caption.37}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces LCFIPlusによって予想される崩壊点の位置の分布}}{51}{figure.caption.38}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces LCFIPlusによって予想される崩壊点の位置と$\chi ^2$値の相関}}{51}{figure.caption.39}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces 終状態$\rm b\bar {b}$での崩壊点\relax }}{54}{figure.caption.41}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces 飛跡対についてのネットワークの概略図}}{55}{figure.caption.42}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces 各終状態での分類クラスのデータ数の比}}{55}{figure.caption.43}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces 訓練データでの分類クラスのデータ数の比}}{56}{figure.caption.44}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces 評価のための飛跡対についてのネットワーク\relax }}{59}{figure.caption.46}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces ネットワークのスコアとクラス分類の効率の関係}}{60}{figure.caption.48}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces 各モデルのROC曲線}}{61}{figure.caption.49}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces 各モデルの混合行列と各モデルの相対値}}{63}{figure.caption.50}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces t-SNEによる次元削減の比較}}{64}{figure.caption.51}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces リカレントニューラルネットワークを用いた崩壊点生成}}{65}{figure.caption.52}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces 崩壊点生成のためのリカレントニューラルネットワーク構造}}{65}{figure.caption.53}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces 系列1ステップについての独自リカレントニューラルネットワーク構造}}{66}{figure.caption.54}%
\contentsline {figure}{\numberline {3.19}{\ignorespaces 独自リカレントニューラルネットワーク構造の解釈}}{67}{figure.caption.55}%
\contentsline {figure}{\numberline {3.20}{\ignorespaces Attentionを組み込んだエンコーダー・デコーダーモデルへの拡張}}{68}{figure.caption.56}%
\contentsline {figure}{\numberline {3.21}{\ignorespaces 独自リカレントニューラルネットワークのAttentionへの拡張}}{69}{figure.caption.57}%
\contentsline {figure}{\numberline {3.22}{\ignorespaces 飛跡順のシャッフル}}{71}{figure.caption.59}%
\contentsline {figure}{\numberline {3.23}{\ignorespaces 標準的なLSTMと独自のネットワークの比較}}{73}{figure.caption.62}%
\contentsline {figure}{\numberline {3.24}{\ignorespaces 各データ属性の効率とスコアの関係}}{74}{figure.caption.63}%
\contentsline {figure}{\numberline {3.25}{\ignorespaces 各データ属性のROC曲線}}{74}{figure.caption.64}%
\contentsline {figure}{\numberline {3.26}{\ignorespaces Attention Weight}}{76}{figure.caption.65}%
\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {4.1}{\ignorespaces 崩壊点検出アルゴリズム\relax }}{78}{figure.caption.66}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces 閾値とSVのタネの効率、純度の関係}}{80}{figure.caption.67}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces 閾値とSVのタネの効率、純度についてのPR曲線}}{81}{figure.caption.68}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces 同一の崩壊チェインと同一の親粒子}}{82}{figure.caption.69}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces 閾値と崩壊点検出の性能の関係-PVのタネ1個\relax }}{83}{figure.caption.70}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces 閾値と崩壊点検出の性能の関係-PVのタネ2個\relax }}{84}{figure.caption.71}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces 閾値と崩壊点検出の性能の関係-PVのタネ3個\relax }}{85}{figure.caption.72}%
\addvspace {10\jsc@mpt }
\contentsline {figure}{\numberline {5.1}{\ignorespaces フレーバータギングの性能に関するROC曲線}}{91}{figure.caption.77}%
\addvspace {10\jsc@mpt }
\addvspace {10\jsc@mpt }
