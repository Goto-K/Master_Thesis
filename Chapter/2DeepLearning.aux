\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{ZeroDeepLearning1}
\citation{ZeroDeepLearning2}
\citation{PythonMLPrograming}
\citation{Dartmouth}
\@writefile{toc}{\contentsline {chapter}{\numberline {第2章}深層学習}{20}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\jsc@mpt }}
\@writefile{lot}{\addvspace {10\jsc@mpt }}
\newlabel{chap:DeepLearning}{{2}{20}{深層学習}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}機械学習と深層学習}{20}{section.2.1}\protected@file@percent }
\newlabel{DL:MachineandDeepLearning}{{2.1}{20}{機械学習と深層学習}{section.2.1}{}}
\citation{PatternRecognitionUsingGeneralizedPortraitMethod}
\citation{TrainingAlgorithmforOptimalMarginClassifiers}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 機械学習の中の深層学習の位置付け}}{21}{figure.caption.13}\protected@file@percent }
\newlabel{1MachineLearning}{{2.1}{21}{機械学習の中の深層学習の位置付け}{figure.caption.13}{}}
\citation{PerceptronPaper}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}パーセプトロン}{22}{section.2.2}\protected@file@percent }
\newlabel{DL:Perceptron}{{2.2}{22}{パーセプトロン}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}単純パーセプトロン}{22}{subsection.2.2.1}\protected@file@percent }
\newlabel{DL:Percep:SimplePerceptron}{{2.2.1}{22}{単純パーセプトロン}{subsection.2.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces 単純パーセプトロン}}{22}{figure.caption.14}\protected@file@percent }
\newlabel{2SimplePerceptron}{{2.2}{22}{単純パーセプトロン}{figure.caption.14}{}}
\citation{ApproximationSuperpositionsSigmoidalFunction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces ヘヴィサイドの階段関数\relax }}{23}{figure.caption.15}\protected@file@percent }
\newlabel{3HeavisideStepFunction}{{2.3}{23}{ヘヴィサイドの階段関数\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}多層パーセプトロン}{23}{subsection.2.2.2}\protected@file@percent }
\newlabel{DL:Percep:MultiLayerPerceptron}{{2.2.2}{23}{多層パーセプトロン}{subsection.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces 多層パーセプトロン}}{23}{figure.caption.16}\protected@file@percent }
\newlabel{4MultiLayerPerceptron}{{2.4}{23}{多層パーセプトロン}{figure.caption.16}{}}
\citation{TensorflowWeb}
\citation{KerasWeb}
\citation{PyTorchWeb}
\citation{CaffeWeb}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}ニューラルネットワーク}{24}{section.2.3}\protected@file@percent }
\newlabel{DL:NeuralNetwork}{{2.3}{24}{ニューラルネットワーク}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}ニューラルネットワークの構造}{24}{subsection.2.3.1}\protected@file@percent }
\newlabel{DL:NN:StructureofNN}{{2.3.1}{24}{ニューラルネットワークの構造}{subsection.2.3.1}{}}
\citation{ReLUpaper}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces 活性化関数\relax }}{25}{figure.caption.17}\protected@file@percent }
\newlabel{5ActivationFunction}{{2.5}{25}{活性化関数\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces ニューラルネットワーク}}{25}{figure.caption.18}\protected@file@percent }
\newlabel{6NeuralNetwork}{{2.6}{25}{ニューラルネットワーク}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}ニューラルネットワークの学習}{27}{subsection.2.3.2}\protected@file@percent }
\newlabel{DL:NN:TrainingofNN}{{2.3.2}{27}{ニューラルネットワークの学習}{subsection.2.3.2}{}}
\citation{SGD}
\citation{RMSProp}
\citation{Adam}
\citation{Backpropagation}
\citation{Autoencoder}
\citation{GenerativeAdversarialNetworks}
\citation{LSTMpaper}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}ディープニューラルネットワーク}{30}{subsection.2.3.3}\protected@file@percent }
\newlabel{DL:NN:DeepNeuralNetwork}{{2.3.3}{30}{ディープニューラルネットワーク}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}リカレントニューラルネットワーク}{30}{section.2.4}\protected@file@percent }
\newlabel{DL:RecurrentNeuralNetwork}{{2.4}{30}{リカレントニューラルネットワーク}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}リカレントニューラルネットワークの構造と学習}{30}{subsection.2.4.1}\protected@file@percent }
\newlabel{DL:RNN:ReccurentNeuralNetwork}{{2.4.1}{30}{リカレントニューラルネットワークの構造と学習}{subsection.2.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces リカレントニューラルネットワーク}}{31}{figure.caption.19}\protected@file@percent }
\newlabel{7RecurrentNeuralNetwork}{{2.7}{31}{リカレントニューラルネットワーク}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces リカレントニューラルネットワークの重みの明示的な表現}}{32}{figure.caption.20}\protected@file@percent }
\newlabel{8RNNWeight}{{2.8}{32}{リカレントニューラルネットワークの重みの明示的な表現}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces リカレントニューラルネットワークの出力方法}}{32}{figure.caption.21}\protected@file@percent }
\newlabel{9RNNOutputs}{{2.9}{32}{リカレントニューラルネットワークの出力方法}{figure.caption.21}{}}
\citation{GRU}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}リカレントニューラルネットワークの問題点}{33}{subsection.2.4.2}\protected@file@percent }
\newlabel{DL:RNN:IssueofRNN}{{2.4.2}{33}{リカレントニューラルネットワークの問題点}{subsection.2.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}長・短期記憶 (Long Short-Term Memory, LSTM)}{33}{subsection.2.4.3}\protected@file@percent }
\newlabel{DL:RNN:LongShortTermMemory}{{2.4.3}{33}{長・短期記憶 (Long Short-Term Memory, LSTM)}{subsection.2.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces LSTMの流れ}}{34}{figure.caption.22}\protected@file@percent }
\newlabel{10LongShortTermMemory}{{2.10}{34}{LSTMの流れ}{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces 単体のLSTM}}{34}{figure.caption.23}\protected@file@percent }
\newlabel{11LSTM}{{2.11}{34}{単体のLSTM}{figure.caption.23}{}}
\newlabel{12ForgetGate}{{2.12a}{36}{忘却ゲート\relax }{figure.caption.24}{}}
\newlabel{sub@12ForgetGate}{{a}{36}{忘却ゲート\relax }{figure.caption.24}{}}
\newlabel{13InputGate}{{2.12b}{36}{入力ゲート\relax }{figure.caption.24}{}}
\newlabel{sub@13InputGate}{{b}{36}{入力ゲート\relax }{figure.caption.24}{}}
\newlabel{14CellUpdate}{{2.12c}{36}{セルの更新\relax }{figure.caption.24}{}}
\newlabel{sub@14CellUpdate}{{c}{36}{セルの更新\relax }{figure.caption.24}{}}
\newlabel{15OutputGate}{{2.12d}{36}{出力ゲート\relax }{figure.caption.24}{}}
\newlabel{sub@15OutputGate}{{d}{36}{出力ゲート\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces LSTMの各ゲートについての図解}}{36}{figure.caption.24}\protected@file@percent }
\citation{BahdanauAttention}
\citation{LuongAttention}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Stacked LSTM}}{37}{figure.caption.25}\protected@file@percent }
\newlabel{16StackedLSTM}{{2.13}{37}{Stacked LSTM}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces 双方向LSTM}}{37}{figure.caption.26}\protected@file@percent }
\newlabel{17BidirectionalLSTM}{{2.14}{37}{双方向LSTM}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Attention}{38}{section.2.5}\protected@file@percent }
\newlabel{DL:Attention}{{2.5}{38}{Attention}{section.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}エンコーダー・デコーダーモデル}{38}{subsection.2.5.1}\protected@file@percent }
\newlabel{DL:Atten:EncoderDecoderModel}{{2.5.1}{38}{エンコーダー・デコーダーモデル}{subsection.2.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Attention}{38}{subsection.2.5.2}\protected@file@percent }
\newlabel{DL:Atten:Attention}{{2.5.2}{38}{Attention}{subsection.2.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces LSTMによるエンコーダー・デコーダーモデル}}{39}{figure.caption.27}\protected@file@percent }
\newlabel{18EncoderDecoderLSTM}{{2.15}{39}{LSTMによるエンコーダー・デコーダーモデル}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces AttentionとLSTMによるエンコーダー・デコーダーモデル}}{39}{figure.caption.28}\protected@file@percent }
\newlabel{19EncoderDecoderAttention}{{2.16}{39}{AttentionとLSTMによるエンコーダー・デコーダーモデル}{figure.caption.28}{}}
\citation{BahdanauAttention}
\citation{LuongAttention}
\citation{AttentionIsAllYouNeed}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Additive Attention と Dot-Product Attention\relax }}{41}{figure.caption.29}\protected@file@percent }
\newlabel{20Attention}{{2.17}{41}{Additive Attention と Dot-Product Attention\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}ハイパーパラメータ}{41}{section.2.6}\protected@file@percent }
\newlabel{DL:HyperParameter}{{2.6}{41}{ハイパーパラメータ}{section.2.6}{}}
\citation{GitHubGotoK}
\@setckpt{Chapter/2DeepLearning}{
\setcounter{page}{43}
\setcounter{equation}{33}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{6}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{17}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{3}
\setcounter{Hfootnote}{6}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{28}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{4}
\setcounter{section@level}{1}
}
