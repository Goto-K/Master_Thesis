\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{ZeroDeepLearning1}
\citation{ZeroDeepLearning2}
\citation{PythonMLPrograming}
\@writefile{toc}{\contentsline {chapter}{\numberline {第2章}深層学習}{18}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\jsc@mpt }}
\@writefile{lot}{\addvspace {10\jsc@mpt }}
\newlabel{chap:DeepLearning}{{2}{18}{深層学習}{chapter.2}{}}
\citation{Dartmouth}
\citation{PatternRecognitionUsingGeneralizedPortraitMethod}
\citation{TrainingAlgorithmforOptimalMarginClassifiers}
\citation{PerceptronPaper}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}機械学習と深層学習}{19}{section.2.1}\protected@file@percent }
\newlabel{DL:MachineandDeepLearning}{{2.1}{19}{機械学習と深層学習}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 機械学習の中の深層学習の位置付け\relax }}{20}{figure.caption.12}\protected@file@percent }
\newlabel{1MachineLearning}{{2.1}{20}{機械学習の中の深層学習の位置付け\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}パーセプトロン}{20}{section.2.2}\protected@file@percent }
\newlabel{DL:Perceptron}{{2.2}{20}{パーセプトロン}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}単純パーセプトロン}{20}{subsection.2.2.1}\protected@file@percent }
\newlabel{DL:Percep:SimplePerceptron}{{2.2.1}{20}{単純パーセプトロン}{subsection.2.2.1}{}}
\citation{ApproximationSuperpositionsSigmoidalFunction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces 単純パーセプトロン\relax }}{21}{figure.caption.13}\protected@file@percent }
\newlabel{2SimplePerceptron}{{2.2}{21}{単純パーセプトロン\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces ヘヴィサイドの階段関数\relax }}{21}{figure.caption.14}\protected@file@percent }
\newlabel{3HeavisideStepFunction}{{2.3}{21}{ヘヴィサイドの階段関数\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}多層パーセプトロン}{21}{subsection.2.2.2}\protected@file@percent }
\newlabel{DL:Percep:MultiLayerPerceptron}{{2.2.2}{21}{多層パーセプトロン}{subsection.2.2.2}{}}
\citation{TensorflowWeb}
\citation{KerasWeb}
\citation{PyTorchWeb}
\citation{CaffeWeb}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces 多層パーセプトロン\relax }}{22}{figure.caption.15}\protected@file@percent }
\newlabel{4MultiLayerPerceptron}{{2.4}{22}{多層パーセプトロン\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}ニューラルネットワーク}{22}{section.2.3}\protected@file@percent }
\newlabel{DL:NeuralNetwork}{{2.3}{22}{ニューラルネットワーク}{section.2.3}{}}
\citation{ReLUpaper}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}ニューラルネットワークの構造}{23}{subsection.2.3.1}\protected@file@percent }
\newlabel{DL:NN:StructureofNN}{{2.3.1}{23}{ニューラルネットワークの構造}{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces 活性化関数\relax }}{24}{figure.caption.16}\protected@file@percent }
\newlabel{5ActivationFunction}{{2.5}{24}{活性化関数\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces ニューラルネットワーク\relax }}{24}{figure.caption.17}\protected@file@percent }
\newlabel{6NeuralNetwork}{{2.6}{24}{ニューラルネットワーク\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}ニューラルネットワークの学習}{25}{subsection.2.3.2}\protected@file@percent }
\newlabel{DL:NN:TrainingofNN}{{2.3.2}{25}{ニューラルネットワークの学習}{subsection.2.3.2}{}}
\citation{SGD}
\citation{RMSProp}
\citation{Adam}
\citation{Backpropagation}
\citation{Autoencoder}
\citation{GenerativeAdversarialNetworks}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}ディープニューラルネットワーク}{28}{subsection.2.3.3}\protected@file@percent }
\newlabel{DL:NN:DeepNeuralNetwork}{{2.3.3}{28}{ディープニューラルネットワーク}{subsection.2.3.3}{}}
\citation{LSTMpaper}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}リカレントニューラルネットワーク}{29}{section.2.4}\protected@file@percent }
\newlabel{DL:RecurrentNeuralNetwork}{{2.4}{29}{リカレントニューラルネットワーク}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}リカレントニューラルネットワークの構造と学習}{29}{subsection.2.4.1}\protected@file@percent }
\newlabel{DL:RNN:ReccurentNeuralNetwork}{{2.4.1}{29}{リカレントニューラルネットワークの構造と学習}{subsection.2.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces リカレントニューラルネットワーク\relax }}{30}{figure.caption.18}\protected@file@percent }
\newlabel{7RecurrentNeuralNetwork}{{2.7}{30}{リカレントニューラルネットワーク\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces リカレントニューラルネットワークの重み\relax }}{30}{figure.caption.19}\protected@file@percent }
\newlabel{8RNNWeight}{{2.8}{30}{リカレントニューラルネットワークの重み\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces リカレントニューラルネットワークの出力方法\relax }}{31}{figure.caption.20}\protected@file@percent }
\newlabel{9RNNOutputs}{{2.9}{31}{リカレントニューラルネットワークの出力方法\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}リカレントニューラルネットワークの問題点}{31}{subsection.2.4.2}\protected@file@percent }
\newlabel{DL:RNN:IssueofRNN}{{2.4.2}{31}{リカレントニューラルネットワークの問題点}{subsection.2.4.2}{}}
\citation{GRU}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}長・短期記憶 (Long Short-Term Memory, LSTM)}{32}{subsection.2.4.3}\protected@file@percent }
\newlabel{DL:RNN:LongShortTermMemory}{{2.4.3}{32}{長・短期記憶 (Long Short-Term Memory, LSTM)}{subsection.2.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces LSTMの流れ\relax }}{33}{figure.caption.21}\protected@file@percent }
\newlabel{10LongShortTermMemory}{{2.10}{33}{LSTMの流れ\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces 単体のLSTM\relax }}{33}{figure.caption.22}\protected@file@percent }
\newlabel{11LSTM}{{2.11}{33}{単体のLSTM\relax }{figure.caption.22}{}}
\newlabel{12ForgetGate}{{2.12a}{35}{忘却ゲート\relax }{figure.caption.23}{}}
\newlabel{sub@12ForgetGate}{{a}{35}{忘却ゲート\relax }{figure.caption.23}{}}
\newlabel{13InputGate}{{2.12b}{35}{入力ゲート\relax }{figure.caption.23}{}}
\newlabel{sub@13InputGate}{{b}{35}{入力ゲート\relax }{figure.caption.23}{}}
\newlabel{14CellUpdate}{{2.12c}{35}{セルの更新\relax }{figure.caption.23}{}}
\newlabel{sub@14CellUpdate}{{c}{35}{セルの更新\relax }{figure.caption.23}{}}
\newlabel{15OutputGate}{{2.12d}{35}{出力ゲート\relax }{figure.caption.23}{}}
\newlabel{sub@15OutputGate}{{d}{35}{出力ゲート\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces LSTMの各ゲートについての図解\relax }}{35}{figure.caption.23}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Stacked LSTM\relax }}{35}{figure.caption.24}\protected@file@percent }
\newlabel{16StackedLSTM}{{2.13}{35}{Stacked LSTM\relax }{figure.caption.24}{}}
\citation{BahdanauAttention}
\citation{LuongAttention}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces 双方向LSTM\relax }}{36}{figure.caption.25}\protected@file@percent }
\newlabel{17BidirectionalLSTM}{{2.14}{36}{双方向LSTM\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Attention}{36}{section.2.5}\protected@file@percent }
\newlabel{DL:Attention}{{2.5}{36}{Attention}{section.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}エンコーダー・デコーダーモデル}{36}{subsection.2.5.1}\protected@file@percent }
\newlabel{DL:Atten:EncoderDecoderModel}{{2.5.1}{36}{エンコーダー・デコーダーモデル}{subsection.2.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces LSTMによるエンコーダー・デコーダーモデル\relax }}{37}{figure.caption.26}\protected@file@percent }
\newlabel{18EncoderDecoderLSTM}{{2.15}{37}{LSTMによるエンコーダー・デコーダーモデル\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Attention}{37}{subsection.2.5.2}\protected@file@percent }
\newlabel{DL:Atten:Attention}{{2.5.2}{37}{Attention}{subsection.2.5.2}{}}
\citation{BahdanauAttention}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces AttentionとLSTMによるエンコーダー・デコーダーモデル\relax }}{38}{figure.caption.27}\protected@file@percent }
\newlabel{19EncoderDecoderAttention}{{2.16}{38}{AttentionとLSTMによるエンコーダー・デコーダーモデル\relax }{figure.caption.27}{}}
\citation{LuongAttention}
\citation{AttentionIsAllYouNeed}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Additive Attention と Dot-Product Attention\relax }}{39}{figure.caption.28}\protected@file@percent }
\newlabel{20Attention}{{2.17}{39}{Additive Attention と Dot-Product Attention\relax }{figure.caption.28}{}}
\citation{GitHubGotoK}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}ハイパーパラメータ}{40}{section.2.6}\protected@file@percent }
\newlabel{DL:HyperParameter}{{2.6}{40}{ハイパーパラメータ}{section.2.6}{}}
\@setckpt{Chapter/2DeepLearning}{
\setcounter{page}{41}
\setcounter{equation}{33}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{8}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{17}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{3}
\setcounter{Hfootnote}{8}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{28}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{4}
\setcounter{section@level}{1}
}
